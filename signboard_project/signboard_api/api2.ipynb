{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "import os   \n",
    "import random    \n",
    "import cv2   \n",
    "import time     \n",
    "import tensorflow as tf\n",
    "import falcon   \n",
    "from falcon_multipart.middleware import MultipartMiddleware   \n",
    "from PIL import Image   \n",
    "from darkflow.net.build import TFNet \n",
    "\n",
    "from keras.models import model_from_json   \n",
    "from keras.preprocessing import image  \n",
    "from keras.preprocessing.image import img_to_array, load_img  \n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.optimizers import SGD     \n",
    "\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.applications.vgg16 import preprocess_input   \n",
    "from keras.applications.vgg16 import decode_predictions   \n",
    "\n",
    "from waitress import serve \n",
    "import shutil \n",
    "import glob\n",
    "\n",
    "\n",
    "from keras import backend as K     \n",
    "config = tf.ConfigProto()   \n",
    "config.gpu_options.allow_growth = True  \n",
    "sess = tf.Session(config=config)   \n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORSを許可　\n",
    "class CORSMiddleware:\n",
    "    def process_request(self, req, res):\n",
    "        res.set_header('Access-Control-Allow-Origin', '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostImage(object):   \n",
    "    def __init__(self):\n",
    "        # darkflowを初期化\n",
    "        options = {\n",
    "            \"model\" : \"cfg/yolov2-signboard0731.cfg\",        \n",
    "            \"load\" : \"bin/signboard0731/yolov2-signboard0731_10000.weights\",\n",
    "            \"threshold\" : 0.1,           \n",
    "            \"gpu\" : 0.9          \n",
    "        }\n",
    "        self.tfnet = TFNet(options)     \n",
    "        \n",
    "        # VGG16を初期化\n",
    "        self.vgg16=VGG16_tabelog()  \n",
    "\n",
    "        \n",
    "    def on_post(self, req, res):\n",
    "        data = req.get_param('file').file.read()\n",
    "        \n",
    "        arr = np.asarray(bytearray(data), dtype=np.uint8)  \n",
    "        img = cv2.imdecode(arr, 1) \n",
    "        predict = self.tfnet.return_predict(img)   \n",
    "        print(predict)\n",
    "        result = []\n",
    "            \n",
    "\n",
    "        for item in predict:\n",
    "            result.append(self.vgg16.predict(img,item)) \n",
    "            \n",
    "        result_json = json.dumps(result, cls=MyEncoder) \n",
    "        print(result_json)\n",
    "        res.status = falcon.HTTP_200  \n",
    "        res.body = result_json   \n",
    "    \n",
    "    # GETは使わない\n",
    "    def on_get(self, req, res):\n",
    "        res.body = '{\"message\": \"画像をPOSTしてください．\"}'  \n",
    "        res.status = falcon.HTTP_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16_tabelog: \n",
    "    def __init__(self):\n",
    "        self.batch_size = 32   \n",
    "        self.file_name = \"../signboard_classifier/vgg16_tabelogimg_cv2out_150\"  \n",
    "        self.label = sorted(glob.glob(\"../signboard_classifier/tabelogimg_cv2out_150/train/*\"))\n",
    "        for i in range(len(self.label)):    \n",
    "            self.label[i]=self.label[i].split(\"/\")[-1]  \n",
    "            \n",
    "        self.zero_list=[0]*len(self.label) \n",
    "        self.node = dict(zip(self.label,self.zero_list))  \n",
    "        self.url = self.label \n",
    "        rep_url_list=[] \n",
    "        for i in self.url:\n",
    "            rep_url = i.replace(\"_\",\"/\") \n",
    "            rep_url = \"https://tabelog.com/\"+rep_url \n",
    "            rep_url_list.append(rep_url)\n",
    "        self.url=rep_url_list \n",
    "        self.url = dict(zip(self.label,self.url))\n",
    "        \n",
    "            \n",
    "        \n",
    "        # モデルの読み込む\n",
    "        json_string = open(self.file_name + \".json\").read()\n",
    "        global model\n",
    "        model = model_from_json(json_string)  \n",
    "        model.load_weights(self.file_name + \".h5\")  \n",
    "        model.compile(            \n",
    "            optimizer = SGD(lr = 0.0001, momentum = 0.9),\n",
    "            loss = \"categorical_crossentropy\",\n",
    "            metrics = [\"accuracy\"]\n",
    "        )\n",
    "        global graph\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "    def predict(self, src, _item): \n",
    "        item = _item\n",
    "        \n",
    "        tlx = item['topleft']['x']\n",
    "        tly = item['topleft']['y']\n",
    "        brx = item['bottomright']['x']\n",
    "        bry = item['bottomright']['y']\n",
    "        conf = item['confidence']\n",
    "\n",
    "        dst = src[tly:bry, tlx:brx]\n",
    "        temp_img = cv2.resize(dst, (224, 224))\n",
    "        temp_img = Image.fromarray(temp_img[:, :, ::-1].copy())\n",
    "\n",
    "        x = img_to_array(temp_img)\n",
    "        x = x.astype(\"float32\")/255.0\n",
    "        x = x.reshape((1, 224, 224, 3))\n",
    "\n",
    "        with graph.as_default():\n",
    "            img_pred = model.predict(x)\n",
    "            name = self.label[np.argmax(img_pred)]\n",
    "            print(name)\n",
    "            item[\"name\"] = name\n",
    "            item[\"node\"] = self.node[name]\n",
    "            item[\"url\"] = self.url[name]\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):  \n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = falcon.API(middleware=[CORSMiddleware(), MultipartMiddleware()])  \n",
    "app.add_route('/gunicorn', PostImage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serve(app, listen='0.0.0.0:18000')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像のpath\n",
    "tabelog_img_input_path=\"\"   \n",
    "tabelog_img_output_path=\"\"\n",
    "store_list = sorted(glob.glob(tabelog_img_input_path+\"/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看板領域の抽出\n",
    "\n",
    "for store in range(len(store_list)):\n",
    "    img_list = sorted(glob.glob(store_list[store]+\"/*\"))\n",
    "    for img in range(len(img_list)):\n",
    "        print(img_list[img])\n",
    "        imgcv=cv2.imread(img_list[img])\n",
    "        if type(imgcv)==np.ndarray:\n",
    "            result=tfnet.return_predict(imgcv)\n",
    "            #print(result)\n",
    "            for i in range(len(result)):\n",
    "                if 0.8<result[i]['confidence']:\n",
    "                    tlx=result[i]['topleft']['x']\n",
    "                    tly=result[i]['topleft']['y']\n",
    "                    brx=result[i]['bottomright']['x']\n",
    "                    bry=result[i]['bottomright']['y']\n",
    "            \n",
    "                    imgcv_out=imgcv[tly:bry,tlx:brx]\n",
    "                    if not os.path.exists(tabelog_img_output_path+store_list[store].split(\"/\")[-1]+\"/\"):\n",
    "                        os.makedirs(tabelog_img_output_path+store_list[store].split(\"/\")[-1]+\"/\")\n",
    "                \n",
    "                    cv2.imwrite(tabelog_img_output_path+store_list[store].split(\"/\")[-1]+\"/\"+str(i)+img_list[img].split(\"/\")[-1],imgcv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一定数以下のデータの店舗は捨てる   \n",
    "import shutil\n",
    "output_store_list = sorted(glob.glob(tabelog_img_output_path+\"/*\")) \n",
    "for output_store in range(len(output_store_list)):\n",
    "    if 20>len(sorted(glob.glob(output_store_list[output_store]+\"/*\"))):\n",
    "        shutil.rmtree(output_store_list[output_store])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセットの分割\n",
    "\n",
    "import glob\n",
    "output_store_list=sorted(glob.glob(tabelog_img_output_path+\"/*\")) \n",
    "\n",
    "for store in range(len(output_store_list)):\n",
    "    img_list = glob.glob(output_store_list[store]+\"/*.jpg\")\n",
    "    val_num=int(len(img_list)*0.2)   \n",
    "    test_num=int(len(img_list)*0.2)   \n",
    "    print(val_num)\n",
    "        \n",
    "    validation_list=random.sample(img_list,val_num)  \n",
    "    for val_img in range(len(validation_list)):\n",
    "        if not os.path.exists(tabelog_img_output_path+\"/validation/\"+output_store_list[store].split(\"/\")[-1]):\n",
    "            os.makedirs(tabelog_img_output_path+\"/validation/\"+output_store_list[store].split(\"/\")[-1])\n",
    "        shutil.move(validation_list[val_img],tabelog_img_output_path+\"/validation/\"+output_store_list[store].split(\"/\")[-1])\n",
    "            \n",
    "    img_list =glob.glob(output_store_list[store]+\"/*.jpg\") \n",
    "                                              \n",
    "    test_list=random.sample(img_list,test_num) \n",
    "    for test_img in range(len(test_list)):\n",
    "        if not os.path.exists(tabelog_img_output_path+\"/test/\"+output_store_list[store].split(\"/\")[-1]):\n",
    "            os.makedirs(tabelog_img_output_path+\"/test/\"+output_store_list[store].split(\"/\")[-1])\n",
    "        shutil.move(test_list[test_img],tabelog_img_output_path+\"/test/\"+output_store_list[store].split(\"/\")[-1])\n",
    "                     \n",
    "    train_list=glob.glob(output_store_list[store]+\"/*.jpg\") \n",
    "    for train_img in range(len(train_list)):\n",
    "        if not os.path.exists(tabelog_img_output_path+\"/train/\"+output_store_list[store].split(\"/\")[-1]):\n",
    "            os.makedirs(tabelog_img_output_path+\"/train/\"+output_store_list[store].split(\"/\")[-1])\n",
    "        shutil.move(train_list[train_img],tabelog_img_output_path+\"/train/\"+output_store_list[store].split(\"/\")[-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#信頼度80%以上が20枚以下を削除\n",
    "import shutil\n",
    "output_store_list = sorted(glob.glob(tabelog_img_output_path+\"/*\")) \n",
    "for output_store in range(len(output_store_list)):\n",
    "    if 20>len(sorted(glob.glob(output_store_list[output_store]+\"/*\"))):\n",
    "        shutil.rmtree(output_store_list[output_store])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLOの設定と学習\n",
    "options = {\n",
    "            \"model\" : \"cfg/yolov2-signboard0731.cfg\",\n",
    "            \"load\" : \"bin/signboard0731/yolov2-signboard0731_10000.weights\",\n",
    "            \"threshold\" : 0.1,\n",
    "            \"gpu\" : 0.9\n",
    "            }\n",
    "tfnet = TFNet(options) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"\"\n",
    "imgcv=cv2.imread(img_path)\n",
    "if type(imgcv)==np.ndarray:\n",
    "    print(\"true\")\n",
    "else:\n",
    "    print(\"false\")  \n",
    "print(type(imgcv))\n",
    "\n",
    "result=tfnet.return_predict(imgcv)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "    tlx=result[i]['topleft']['x']\n",
    "    tly=result[i]['topleft']['y']\n",
    "    brx=result[i]['bottomright']['x']\n",
    "    bry=result[i]['bottomright']['y']\n",
    "    \n",
    "    imgcv_out=imgcv[tly:bry,tlx:brx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
